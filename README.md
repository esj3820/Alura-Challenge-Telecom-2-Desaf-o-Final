# Alura-Challenge-Telecom-2-Desaf-o-Final

Telecom X
üéØ Misi√≥n del Proyecto
El objetivo principal de este proyecto es desarrollar un modelo predictivo robusto para identificar a los clientes con alta probabilidad de cancelar sus servicios (Churn), permitiendo a la empresa anticiparse y tomar acciones proactivas. Este es un problema de clasificaci√≥n binaria, donde la variable objetivo es Churn (1 si el cliente se va, 0 si no).
La m√©trica clave priorizada para este proyecto es el Recall (sensibilidad) para la clase positiva (Churn = 1), con el fin de minimizar los falsos negativos y asegurar la identificaci√≥n de la mayor cantidad posible de clientes en riesgo de abandono.
üß† Tareas Realizadas
El proyecto sigui√≥ una metodolog√≠a estructurada que incluy√≥ las siguientes tareas:
‚Ä¢ Preparaci√≥n de Datos: Tratamiento, codificaci√≥n y normalizaci√≥n de la informaci√≥n.
‚Ä¢ An√°lisis de Correlaci√≥n y Selecci√≥n de Variables: Identificaci√≥n de las caracter√≠sticas m√°s relevantes.
‚Ä¢ Entrenamiento de Modelos de Clasificaci√≥n: Se probaron tres tipos de modelos: Decision Tree, Random Forest y CatBoost.
‚Ä¢ Evaluaci√≥n del Rendimiento: Utilizando m√©tricas clave como Accuracy, Precision, Recall y F1-score.
‚Ä¢ Interpretaci√≥n de Resultados: Incluyendo la importancia de las variables para el modelo.
‚Ä¢ Conclusi√≥n Estrat√©gica: Se√±alando los principales factores de influencia en la cancelaci√≥n de servicios.
üõ†Ô∏è Bibliotecas Utilizadas
El desarrollo del proyecto se realiz√≥ utilizando las siguientes bibliotecas de Python:
‚Ä¢ pandas
‚Ä¢ matplotlib.pyplot
‚Ä¢ numpy
‚Ä¢ seaborn
‚Ä¢ joblib, pickle
‚Ä¢ sklearn.base, sklearn.compose, sklearn.ensemble, sklearn.linear_model, sklearn.metrics, sklearn.model_selection, sklearn.pipeline, sklearn.preprocessing, sklearn.tree
‚Ä¢ imblearn.over_sampling (SMOTE, ADASYN, RandomOverSampler)
‚Ä¢ imblearn.under_sampling (TomekLinks)
‚Ä¢ catboost
‚Ä¢ scipy.stats
‚Ä¢ statsmodels.stats.outliers_influence
üìä An√°lisis Exploratorio de Datos (EDA) y Preparaci√≥n
‚Ä¢ Se utiliz√≥ un dataset normalizado de un desaf√≠o anterior, con registros sin valores nulos.
‚Ä¢ La columna customerID fue eliminada al considerarse irrelevante para el modelado.
‚Ä¢ Se aplic√≥ codificaci√≥n (encoding) a las variables:
    ‚ó¶ Columnas binarias ('Yes'/'No') se transformaron a 1 y 0.
    ‚ó¶ Variables categ√≥ricas como Genero_Cliente, Servicio_Internet, Tipo_Contrato, Metodo_Pago se codificaron usando OneHotEncoder.
‚Ä¢ Se identific√≥ una fuerte correlaci√≥n entre Charges.Monthly y Charges.Total, lo que llev√≥ a la eliminaci√≥n de Charges.Monthly para simplificar el conjunto de datos.
‚Ä¢ El an√°lisis de correlaci√≥n se centr√≥ en variables con una correlaci√≥n absoluta superior al 15% con Churn.
‚Ä¢ El an√°lisis de multicolinealidad fue omitido debido a que los modelos seleccionados no son sensibles a este fen√≥meno.
Hallazgos Clave del EDA:
‚Ä¢ Desequilibrio de Clases: Se observ√≥ una proporci√≥n desigual entre las clases 'Churn No' y 'Churn S√≠'.
‚Ä¢ Antig√ºedad (Tenure) y Churn: La mayor deserci√≥n ocurre en los primeros 12 meses de permanencia, siendo los meses 0 a 6 los de mayor abandono.
‚Ä¢ Categor√≠as con Mayor Churn: Se identificaron las 10 categor√≠as de caracter√≠sticas con el porcentaje m√°s alto de abandono de clientes, como se muestra en los gr√°ficos generados.
üì¶ Modelos Probados y Resultados Clave
Se probaron y optimizaron tres modelos de clasificaci√≥n, enfoc√°ndose en maximizar el Recall para la clase 1 (Churn S√≠).
1. DecisionTreeClassifier
‚Ä¢ Sin optimizaciones: El modelo inicial mostr√≥ un Recall de solo el 48% para la clase Churn S√≠, consider√°ndose "pr√°cticamente in√∫til" para el objetivo.
‚Ä¢ Con Validaci√≥n Cruzada: Las m√©tricas se mantuvieron similares (Recall 49%), indicando estabilidad y buena generalizaci√≥n, pero sin mejora en el recall para la clase de inter√©s.
‚Ä¢ Con Balanceo de Clases: Se probaron RandomOverSampler, SMOTE, ADASYN y TomekLinks. RandomOverSampler demostr√≥ ser la t√©cnica con el mejor Recall (promedio de 0.8122) para la clase Churn S√≠, a pesar de una menor precisi√≥n, y tambi√©n el mejor F1-score global.
‚Ä¢ Con Optimizaci√≥n de Par√°metros (GridSearchCV): Tras la optimizaci√≥n, se lograron mejoras en las m√©tricas de clasificaci√≥n y la matriz de confusi√≥n. El pipeline optimizado fue guardado.
2. CatBoost
‚Ä¢ Sin optimizaciones y con Validaci√≥n Cruzada: Al igual que Decision Tree, CatBoost mostr√≥ un bajo Recall para la clase Churn S√≠ (alrededor del 48-49%) en sus versiones iniciales.
‚Ä¢ Con Balanceo de Clases: El balanceo utilizando una relaci√≥n de pesos de clase calculada (n_class0 / n_class1) ofreci√≥ resultados "mucho mejores" en comparaci√≥n con el balanceo autom√°tico (auto_class_weights='Balanced').
‚Ä¢ Con Optimizaci√≥n de Par√°metros (RandomizedSearchCV): Se optimizaron los hiperpar√°metros del modelo, priorizando el recall. El modelo optimizado y su pipeline tambi√©n fueron guardados.
3. RandomForestClassifier
‚Ä¢ Sin optimizaciones: Similar a los otros modelos, el RandomForest inicial tuvo un Recall de solo el 48% para la clase Churn S√≠, siendo poco √∫til para el objetivo.
‚Ä¢ Con Validaci√≥n Cruzada: Las m√©tricas se mantuvieron estables (Recall 48%), confirmando la consistencia del modelo.
‚Ä¢ Con Balanceo de Clases: Se probaron diversas t√©cnicas de muestreo, incluyendo RandomOverSampler y class_weight='balanced'. RandomOverSampler result√≥ ser nuevamente la t√©cnica con el mejor Recall para esta clase.
‚Ä¢ Con Optimizaci√≥n de Par√°metros (RandomizedSearchCV): El RandomForestClassifier optimizado logr√≥ un rendimiento significativamente mejor. Predijo correctamente al 90% de los clientes Churn S√≠ y al 61% de los Churn No. El recall medio para la clase 1 fue de 0.898 con un intervalo de confianza del 95% de (0.871, 0.923). Este modelo es considerado aceptable para el objetivo del proyecto.
‚Ä¢ Importancia de Variables (Feature Importance): Se identificaron las caracter√≠sticas con una importancia superior al 2% para el modelo RandomForest optimizado.
üìà Resumen y Comparaci√≥n de Modelos Optimizados
Se gener√≥ una tabla comparativa y un gr√°fico de barras para visualizar las m√©tricas clave (Accuracy, Precision_Clase_1, Recall_Clase_1, F1-Score_Clase_1) de las versiones optimizadas de DecisionTree, CatBoost y RandomForest.
El gr√°fico de Recall para la Clase 1 (Churn=Yes) es la m√©trica m√°s relevante para este proyecto, mostrando claramente el rendimiento superior del RandomForestClassifier optimizado en la identificaci√≥n de clientes en riesgo de abandono.
üìÅ Archivos Clave Generados
‚Ä¢ df_codificado.csv: Dataset procesado y codificado.
‚Ä¢ graf_01_torta_churn.png: Distribuci√≥n de Churn.
‚Ä¢ graf_02_desercion_primer_a√±o.png: Clientes que abandonaron en el primer a√±o.
‚Ä¢ graf_03_top_10_churn.png: Top 10 categor√≠as con mayor porcentaje de churn.
‚Ä¢ mapa_de_calor_correlacion_churn.png: Mapa de calor de correlaciones con Churn.
‚Ä¢ MC_*.png: Matrices de confusi√≥n para cada modelo y t√©cnica de balanceo/optimizaci√≥n.
‚Ä¢ ROC_*.png: Curvas ROC para cada modelo y pipeline optimizado.
‚Ä¢ graf_DTC_recall_por_tecnica_balaceo.png: Recall y F1-Score de DecisionTree por t√©cnica de balanceo.
‚Ä¢ graf_RF_recall_por_tecnica_balaceo.png: Recall y F1-Score de RandomForest por t√©cnica de balanceo.
‚Ä¢ graf_RF_importancias.png: Importancia de las caracter√≠sticas para RandomForest.
‚Ä¢ graf_recall_por_modelo.png: Comparaci√≥n final del Recall de los modelos optimizados.
‚Ä¢ pipeline_dt_optimizado.pkl: Pipeline optimizado de Decision Tree.
‚Ä¢ pipeline_CatBoost_optimizado.pkl: Pipeline optimizado de CatBoost.
‚Ä¢ pipeline_RandomForest_optimizado.pkl: Pipeline optimizado de RandomForest.

--------------------------------------------------------------------------------
